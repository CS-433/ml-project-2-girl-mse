{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68fbd415",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe6643f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import logomaker as lm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a14582b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "folder = ''\n",
    "\n",
    "# Constructing the input \n",
    "data_off = pd.read_csv(folder + 'off_sequences.txt', header=0)\n",
    "data_on = pd.read_csv(folder + 'on_sequences.txt', header=0)\n",
    "\n",
    "data = pd.concat((data_off, data_on))\n",
    "\n",
    "original_df = pd.DataFrame(data)\n",
    "\n",
    "original_df['Sequences'] = original_df['Sequences'].apply(list)\n",
    "\n",
    "expanded_df = pd.DataFrame(original_df['Sequences'].tolist(), index=original_df.index)\n",
    "result_df = pd.concat([original_df, expanded_df], axis=1)\n",
    "result_df = result_df.drop('Sequences', axis=1)\n",
    "\n",
    "# Negative Charge D, E: 0, 1 \n",
    "# Positive Charge R, H, K: 2,3,4\n",
    "# Polar Uncharged: S, T, C, P, N, Q: 5,6,7,8,9,10\n",
    "# Nonpolar uncharged: G , A, V, L , M, I: 11, 12, 13, 14,15, 16\n",
    "# Aromatic: F, Y, W: 17, 18, 19\n",
    "\n",
    "\n",
    "amino_acid_mapping = {'D': 0, 'E': 1, 'R': 2, 'H': 3, 'K': 4,\n",
    "                      'S': 5, 'T': 6, 'C': 7, 'P': 8, 'N': 9, 'Q': 10,\n",
    "                      'G': 11, 'A': 12, 'V': 13, 'L': 14, 'M': 15, 'I': 16,\n",
    "                      'F': 17, 'Y': 18, 'W': 19, '-': -1, 'X': -1}\n",
    "\n",
    "# Apply mapping to each element in the DataFrame\n",
    "result_df_mapped = result_df.applymap(lambda x: amino_acid_mapping[x])\n",
    "result_df_encoded = pd.get_dummies(result_df_mapped , prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f9d6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the labels\n",
    "labels_off = pd.DataFrame({'label': 0}, index=range(len(data_off)))\n",
    "labels_on = pd.DataFrame({'label': 1}, index=range(len(data_off), len(data_off)+ len(data_on)) )\n",
    "labels = pd.concat((labels_off, labels_on))\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "# Shuffling the data\n",
    "indices = np.arange(len(data))\n",
    "np.random.shuffle(indices)\n",
    "data = data.iloc[indices]\n",
    "labels = labels.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "872e8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df_encoded, labels, train_size = 0.8 ,test_size=0.2, shuffle = True)\n",
    "chars = X_train.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "# Train the XGBoost model with the default parameters\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "num_zeros, num_ones = count_classes(labels)\n",
    "params = {'objective': 'binary:logistic', 'eval_metric': 'error'} \n",
    "bst = xgb.train(params, dtrain, num_boost_round = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77599341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_train_xgboost(X_train, y_train, X_test, y_test, max_depths = [2,3,4,5,10], min_child_weights = [0,1,2,5,10], early_stopping_rounds=10, num_boost_round = 100):    '''\n",
    "    This funciton performs grid search through \n",
    "    parameters that are influencing the probability of overfitting\n",
    "    It returns the values for AUC-ROC for the \n",
    "    best model and the values used for training\n",
    "    '''\n",
    "    best_params = None\n",
    "    best_acc = 0\n",
    "    num_zeros, num_ones = count_classes(y_train)\n",
    "    for max_d in max_depths:\n",
    "        for min_child in min_child_weights:\n",
    "            params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': max_d, 'min_child_weight': min_child}\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "            dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "            model = xgb.train(params, dtrain, evals=[(dtest, 'test')], \n",
    "                          early_stopping_rounds=early_stopping_rounds, verbose_eval=False)\n",
    "            preds = model.predict(dtest)\n",
    "            preds = np.round(preds)\n",
    "            preds = [int(pred) for pred in preds]\n",
    "            acc = accuracy_score (y_test, preds)\n",
    "            print('Accuracy with ', params, 'is ', \"%.4f \" % (acc))\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_params = params\n",
    "\n",
    "    print(\"Best ACC:\", best_acc)\n",
    "    print(\"Best params:\", best_params)\n",
    "    return best_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a436143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 2, 'min_child_weight': 0} is 0.6316\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 2, 'min_child_weight': 1} is 0.6497\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 2, 'min_child_weight': 2} is 0.6348\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 2, 'min_child_weight': 5} is 0.6107\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 2, 'min_child_weight': 10} is 0.6225\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 3, 'min_child_weight': 0} is 0.6439\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 3, 'min_child_weight': 1} is 0.6770\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 3, 'min_child_weight': 2} is 0.7043\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 3, 'min_child_weight': 5} is 0.6380\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 3, 'min_child_weight': 10} is 0.6225\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 4, 'min_child_weight': 0} is 0.6406\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 4, 'min_child_weight': 1} is 0.6679\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 4, 'min_child_weight': 2} is 0.6952\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 4, 'min_child_weight': 5} is 0.6380\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 4, 'min_child_weight': 10} is 0.6225\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 5, 'min_child_weight': 0} is 0.6225\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 5, 'min_child_weight': 1} is 0.6588\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 5, 'min_child_weight': 2} is 0.6952\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 5, 'min_child_weight': 5} is 0.6380\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 5, 'min_child_weight': 10} is 0.6225\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 10, 'min_child_weight': 0} is 0.6406\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 10, 'min_child_weight': 1} is 0.6439\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 10, 'min_child_weight': 2} is 0.6952\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 10, 'min_child_weight': 5} is 0.6380\n",
      "Accuracy with {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 10, 'min_child_weight': 10} is 0.6225\n",
      "Best ACC: 0.7043\n",
      "Best params: {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 3, 'min_child_weight': 2}\n"
     ]
    }
   ],
   "source": [
    "def cross_val_accuracy(params, num_boost_round, X, y, k=10):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation for XGBoost model accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    - params (dict): XGBoost model hyperparameters.\n",
    "    - num_boost_round (int): Number of boosting rounds for XGBoost.\n",
    "    - X (DataFrame): Features for the dataset.\n",
    "    - y (Series): Target variable for the dataset.\n",
    "    - k (int, optional): Number of folds for cross-validation. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    - float: Mean accuracy across all folds.\n",
    "    \"\"\"\n",
    "    chunk_size = len(X) // k\n",
    "    accuracies = []\n",
    "\n",
    "    for i in range(k):\n",
    "        start = i * chunk_size\n",
    "        end = (i + 1) * chunk_size if i < k - 1 else len(X)\n",
    "\n",
    "        X_val_fold = X.iloc[start:end]\n",
    "        y_val_fold = y.iloc[start:end]\n",
    "\n",
    "        X_train_fold = pd.concat([X.iloc[:start], X.iloc[end:]])\n",
    "        y_train_fold = pd.concat([y.iloc[:start], y.iloc[end:]])\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train_fold, label=y_train_fold)\n",
    "        dval = xgb.DMatrix(X_val_fold, label=y_val_fold)\n",
    "\n",
    "        bst = xgb.train(params, dtrain, num_boost_round=num_boost_round)\n",
    "\n",
    "        preds = bst.predict(dval)\n",
    "        preds = np.round(preds)\n",
    "        acc = accuracy_score(y_val_fold, preds)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    return np.mean(accuracies)\n",
    "\n",
    "param_grid = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': [2, 3, 4, 5, 10],\n",
    "              'min_child_weight': [0, 1, 2, 5, 10]}\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_params = None\n",
    "\n",
    "# Perform cross-validation\n",
    "for max_depth in param_grid['max_depth']:\n",
    "    for min_child_weight in param_grid['min_child_weight']:\n",
    "        current_params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': max_depth,\n",
    "                          'min_child_weight': min_child_weight}\n",
    "        current_accuracy = cross_val_accuracy(current_params, num_boost_round=100, X=result_df_encoded, y=labels, k=10)\n",
    "\n",
    "        print(f\"Accuracy with {current_params} is {current_accuracy:.4f}\")\n",
    "\n",
    "        if current_accuracy > best_accuracy:\n",
    "            best_accuracy = current_accuracy\n",
    "            best_params = current_params\n",
    "\n",
    "print(f\"Best ACC: {best_accuracy:.4f}\")\n",
    "print(f\"Best params: {best_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
